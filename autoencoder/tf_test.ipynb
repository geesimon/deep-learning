{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geesi\\Anaconda3\\envs\\dlnd\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm plotting an example image from the MNIST dataset. These are 28x28 grayscale images of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 784))\n",
    "targets_ = tf.placeholder(tf.int64, [None])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "input_layer = tf.reshape(inputs_, [-1, 28, 28, 1])\n",
    "conv1 = tf.layers.conv2d(inputs=input_layer,filters=32,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "conv2 = tf.layers.conv2d(inputs=pool1,filters=64,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout = tf.layers.dropout(inputs=dense, rate=keep_prob)\n",
    "\n",
    "logits = tf.layers.dense(inputs=dropout, units=10) \n",
    "\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=targets_, logits=logits)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), targets_)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll write a bit of code to train the network. I'm not too interested in validation here, so I'll just monitor the training loss. \n",
    "\n",
    "Calling `mnist.train.next_batch(batch_size)` will return a tuple of `(images, labels)`. We're not concerned with the labels here, we just need the images. Otherwise this is pretty straightfoward training with TensorFlow. We initialize the variables with `sess.run(tf.global_variables_initializer())`. Then, run the optimizer and get the loss with `batch_cost, _ = sess.run([cost, opt], feed_dict=feed)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99  - Validation Accuracy: 0.964900016784668, Loss:0.11545532196760178\n",
      "Epoch 199 - Validation Accuracy: 0.978600025177002, Loss:0.06902900338172913\n",
      "Epoch 299 - Validation Accuracy: 0.9797999858856201, Loss:0.05451254919171333\n",
      "Epoch 399 - Validation Accuracy: 0.9846000075340271, Loss:0.05311987176537514\n",
      "Epoch 499 - Validation Accuracy: 0.9815999865531921, Loss:0.05718529596924782\n",
      "Epoch 599 - Validation Accuracy: 0.9847000241279602, Loss:0.04626205191016197\n",
      "Epoch 699 - Validation Accuracy: 0.9886000156402588, Loss:0.03195573762059212\n",
      "Epoch 799 - Validation Accuracy: 0.9879999756813049, Loss:0.03617949038743973\n",
      "Epoch 899 - Validation Accuracy: 0.989799976348877, Loss:0.028688764199614525\n",
      "Epoch 999 - Validation Accuracy: 0.9846000075340271, Loss:0.042116839438676834\n",
      "Epoch 1099 - Validation Accuracy: 0.9900000095367432, Loss:0.030429242178797722\n",
      "Epoch 1199 - Validation Accuracy: 0.991599977016449, Loss:0.028416229411959648\n",
      "Epoch 1299 - Validation Accuracy: 0.9905999898910522, Loss:0.028006451204419136\n",
      "Epoch 1399 - Validation Accuracy: 0.9915000200271606, Loss:0.026115911081433296\n",
      "Epoch 1499 - Validation Accuracy: 0.9914000034332275, Loss:0.02833092398941517\n",
      "Epoch 1599 - Validation Accuracy: 0.989799976348877, Loss:0.03129516541957855\n",
      "Epoch 1699 - Validation Accuracy: 0.9879999756813049, Loss:0.03823298215866089\n",
      "Epoch 1799 - Validation Accuracy: 0.9927999973297119, Loss:0.01785162277519703\n",
      "Epoch 1899 - Validation Accuracy: 0.9909999966621399, Loss:0.028280679136514664\n",
      "Epoch 1999 - Validation Accuracy: 0.9914000034332275, Loss:0.028920257464051247\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 100\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for ii in range(2000):      \n",
    "    batch = mnist.train.next_batch(batch_size, shuffle=True)\n",
    "    feed = {inputs_: batch[0], targets_: batch[1], keep_prob: 0.4}\n",
    "    batch_cost, _ = sess.run([cross_entropy, train_step], feed_dict=feed)\n",
    "\n",
    "    #print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "    #        \"Training loss: {:.4f}\".format(batch_cost))\n",
    "    if (ii % 100 == 99):\n",
    "        feed = {inputs_: mnist.test.images, targets_: mnist.test.labels, keep_prob:1}\n",
    "        loss, valid_accuracy = sess.run([cross_entropy, accuracy], feed_dict=feed)\n",
    "            \n",
    "        print('Epoch {:<3} - Validation Accuracy: {}, Loss:{}'.format(ii, valid_accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
